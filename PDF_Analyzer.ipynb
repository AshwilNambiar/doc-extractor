{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwilNambiar/doc-extractor/blob/main/PDF_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuiDhbqL5hp1"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install pandas\n",
        "!pip install langchain\n",
        "!pip install chromadb\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwGaTS_9Wzqz"
      },
      "outputs": [],
      "source": [
        "!pip install PyMUPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0wt7TbL4dX9"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import time\n",
        "import re\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import tempfile\n",
        "import fitz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBSlSZpr4dzy"
      },
      "outputs": [],
      "source": [
        "# Set OpenAI API key\n",
        "OPENAI_API_KEY = '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'\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCDasC8a44J8"
      },
      "outputs": [],
      "source": [
        "predefined_questions = [\n",
        "            \"Are there any Mergers made by the compnay\",\n",
        "            \"Are there any Acquisitions made by the company?\",\n",
        "            \"What are identified as the key revenue streams for the company?\",\n",
        "            \"Which key service areas does the company focus on?\",\n",
        "            \"Does the report provide information on Year-over-Year (YoY) growth?\",\n",
        "           \"What are the company's targets for the upcoming year?\",\n",
        "           \"Has the company initiated any Environmental, Social, and Governance (ESG) programs?\",\n",
        "           \"What ESG related actions has the company taken in the current year,and what are the plans for the next year?\",\n",
        "           \"How does the company approach the process of implementing change to achieve its management goals for next year?\",\n",
        "            \"What level of investment is the company planning for the next year?\",\n",
        "           \"In which sector does the company primarily operate?\",\n",
        "           \"How extensive is the company's global presence?\",\n",
        "           \"In which countries or regions are the company's business operations spread?\",\n",
        "           \"What is the global footprint of the company?\",\n",
        "            \"Which continents or countries contribute most significantly to the company's revenue streams?\",\n",
        "            \"Can you elaborate on their activities in high-risk regions, potential exposure to sanctions violations, and their compliance measures regarding Economic Sanction Review Application and Compliance Advanced Research Application?\",\n",
        "           \"What impact have natural disasters had on the company's business in the reported year?\",\n",
        "           \"What impacts of climate change were observed on the company's operations during the year of the report?\",\n",
        "           \"Did the business experience any seasonal changes that influenced the company's business operations in the past year?\",\n",
        "           \"How do seasonal changes influence the company's business?\",\n",
        "           \"How has the company's executive team performed against their set targets/goals?\",\n",
        "            \"Can you summarize the report's highlights in terms of Mergers&Acquisitions,financial performance, strategic developments,key performance indicators, financial metrics, Net Sales,Gross Profit,Operating Expenses,EBIT, Net Income,Earnings per Share and any emerging trends\",\n",
        "            #\"Can you summarize the report's highlights in terms of financial performance,strategic developments and future outlook\",\n",
        "            \"What all acquisitions were made by the company in last 3-5 years? Provide Details\",\n",
        "           \"How has the acquisitions helped / added valued to the existing business? Provide Details\",\n",
        "           \"What is the strategic focus area for the company for the coming years with all the mergers & acquisitions?\",\n",
        "           \"What is the revenue / income stream / sources for the company? Please elaborate in detail\",\n",
        "            \"What are the business areas that the company operate on? Provide details\",\n",
        "            \"How is the financial health of the company?\",\n",
        "            \"Could you provide an overview of the company's financial well-being and stability?\",\n",
        "            \"Considering factors like profitability, liquidity, debt levels, and growth prospects, assess the financial health of the company?\",\n",
        "            \"Considering all the financial metrics, would you rate the company's financial health as strong, moderate, or weak? What are the key strengths and weaknesses in its financial position\",\n",
        "            \"What are the company's strategy and goals for the upcoming years? Please highlight\",\n",
        "            \"What are the internal controls and effective risk management practices that are in place? Provide Details\",\n",
        "            \"Can you Provide management's perspective on the company's performance and prospects.\",\n",
        "            \"What are the company's risks and opportunities?\",\n",
        "            \"Management's perspective about the business and its competitive position?\",\n",
        "            \"Does the company have a strong competitive advantage such as brand recognition, patents, customer loyalty, unique assets, or network effects? Provide details\",\n",
        "            \"‚Å†Are there any disclosures of competitors and similar companies to understand how the company compares to its peers and industry benchmark? Provide details\"\n",
        "        ]\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo-0125', temperature=0.1)\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoeydDPD5B1x"
      },
      "outputs": [],
      "source": [
        "class Document:\n",
        "    def __init__(self, text, metadata={}):\n",
        "        self.page_content = text\n",
        "        self.metadata = metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DSPJewP5HJp"
      },
      "outputs": [],
      "source": [
        "class PDFprocessor:\n",
        "    def __init__(self, filepaths):\n",
        "\n",
        "        self.filepaths=filepaths\n",
        "\n",
        "\n",
        "    def load_pdf(self):\n",
        "        document_data = []\n",
        "        for file_path in self.filepaths:\n",
        "            # Identify file type based on extension\n",
        "         if file_path.endswith(\".pdf\"):\n",
        "            doc = fitz.open(file_path)\n",
        "            for page_num, page in enumerate(doc):\n",
        "                text = page.get_text()\n",
        "                if text:  # Make sure there's text before appending\n",
        "                    document_data.append({\"text\": text, \"page_number\": page_num + 1, \"file_name\": file_path})\n",
        "            doc.close()\n",
        "        return document_data\n",
        "\n",
        "    def split_pdf(self, document_data):\n",
        "      text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "      documents = []\n",
        "      for page_data in document_data:\n",
        "         page_text = page_data[\"text\"]\n",
        "         page_chunks = text_splitter.split_text(page_text)\n",
        "         for i, chunk in enumerate(page_chunks):\n",
        "            page_number = page_data[\"page_number\"]  # Retrieve page number from metadata\n",
        "            metadata = {\"page_number\": page_number}  # Adjust for chunk numbering\n",
        "            document = Document(chunk, metadata=metadata)\n",
        "            documents.append(document)\n",
        "      #st.write(documents[7])\n",
        "      return documents\n",
        "\n",
        "    def vectorstore_and_chain(self, documents):\n",
        "        embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "        try:\n",
        "            vectordb = Chroma.from_documents(documents, embeddings)\n",
        "        except openai.RateLimitError as e:\n",
        "            time.sleep(e.http_body[\"backoff\"])\n",
        "            vectordb = Chroma.from_documents(documents, embeddings)\n",
        "        template = \"\"\"Imagine you are a Risk Analyst responsible for evaluating the various reports of a company.\n",
        "       Your primary duty is to answer questions in suitable format and provide insights based on the Relevant information fetched from the report.\n",
        "       Focus on details of Mergers, Acquisitions ,key performance indicators, financial metrics like Net Sales,Gross Profit, Operating Expenses,EBIT, Net Income,Earnings per Share,profitability, liquidity, debt levels,growth prospects and so on.\n",
        "       Assess the overall financial health and risks of the company, delve into strategic initiatives, and highlight any significant events or risks mentioned in the report.\n",
        "       If statistical,transactional details are available in the report, provide them along with the insights.\n",
        "       Relevant information:{context}\n",
        "       Question: For the company,{question}\n",
        "       Answer:\"\"\"\n",
        "        #s_search=vectorsearch(vectordb,\"Any Mergers\")\n",
        "        #print(s_search)\n",
        "\n",
        "        QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
        "        qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm,\n",
        "            retriever=vectordb.as_retriever(search_kwargs={\"k\": 5}),\n",
        "            return_source_documents=True,\n",
        "            chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "        )\n",
        "\n",
        "        return qa_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg6-MHbC5Qro"
      },
      "outputs": [],
      "source": [
        "class QuestionAnswerer:\n",
        "    def __init__(self):\n",
        "        self.total_questions_answered = 0\n",
        "\n",
        "    def answer_questions(self, questions, qa_chain):\n",
        "\n",
        "        answers = []\n",
        "        source_page_numbers = []\n",
        "\n",
        "        for question in questions:\n",
        "            response = qa_chain.invoke({\"query\": question}, max_tokens=1000)\n",
        "            answer = response[\"result\"]\n",
        "            source_1 = response[\"source_documents\"]\n",
        "            #reordering = LongContextReorder(descending=True)\n",
        "            #source= reordering.transform_documents(source_1)\n",
        "            metadata_list = [doc.metadata for doc in source_1]\n",
        "            source_page_numbers.append(set(page['page_number'] for page in metadata_list))\n",
        "            answers.append(answer)\n",
        "\n",
        "        qna_data = pd.DataFrame({\n",
        "            \"Question Number\": [self.total_questions_answered + i + 1 for i in range(len(questions))],\n",
        "            \"Question\": questions,\n",
        "            \"Answer\": answers,\n",
        "            \"Page Numbers\": source_page_numbers\n",
        "        })\n",
        "\n",
        "        self.total_questions_answered += len(qna_data)\n",
        "        return qna_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh5cIFuyOfyZ"
      },
      "outputs": [],
      "source": [
        "def process_pdf(filepaths):\n",
        "    processed_data_list = []\n",
        "\n",
        "\n",
        "    try:\n",
        "            pdf_processor = PDFprocessor(filepaths)\n",
        "            document_data = pdf_processor.load_pdf()\n",
        "            print(f\"Sample of document data: {document_data[:1]}\")\n",
        "            if not document_data:\n",
        "                print(f\"No content found in the PDF at {filepaths}.\")  # Debugging statement\n",
        "             #   continue\n",
        "\n",
        "            #keywords = pdf_processor.extract_document_keywords(document_data)\n",
        "\n",
        "            documents = pdf_processor.split_pdf(document_data)\n",
        "            chain = pdf_processor.vectorstore_and_chain(documents)\n",
        "            question_answerer = QuestionAnswerer()\n",
        "            batch_qna_data = question_answerer.answer_questions(predefined_questions, chain)\n",
        "\n",
        "            print(f\"Batch Q&A Data for {filepaths}: {batch_qna_data}\")  # Debugging statement\n",
        "            processed_data_list.extend(batch_qna_data.values.tolist())\n",
        "\n",
        "    except Exception as e:\n",
        "            print(f\"An error occurred during processing {filepaths}: {str(e)}\")  # Debugging statement\n",
        "           # continue\n",
        "\n",
        "    return processed_data_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmiy05V5O-D0"
      },
      "outputs": [],
      "source": [
        "def format_output(processed_data):\n",
        "   try:\n",
        "        if processed_data:\n",
        "            df = pd.DataFrame(processed_data, columns=[\"Question Number\", \"Question\", \"Answer\", \"Page Numbers\"])\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\", mode='w+', dir=os.getcwd()) as f:\n",
        "                df.to_csv(f.name, index=False)\n",
        "                csv_filepath = f.name\n",
        "\n",
        "            formatted_output = f\"<div style='text-align: left; margin-left: 20px;'>\"\n",
        "            # formatted_output += f\"<h3>Document Summary:</h3><p>{summary}</p><hr>\"\n",
        "\n",
        "            for item in processed_data:\n",
        "                question_number, question, answer, page_numbers = item\n",
        "\n",
        "                # Assuming each item in page_numbers is a dict with a key 'page_number'\n",
        "                #unique_page_numbers = sorted(set(page['page_number'] for page in page_numbers))\n",
        "                formatted_page_numbers = \", \".join(map(str, page_numbers))\n",
        "\n",
        "                formatted_output += f\"<h4>{question_number}. {question}</h4>\"\n",
        "\n",
        "                # Handle list-like format in the answer\n",
        "                if '\\n' in answer or answer.strip().isdigit():\n",
        "                    answer_lines = answer.split('\\n')\n",
        "                    formatted_output += \"<ul>\"\n",
        "                    for line in answer_lines:\n",
        "                        formatted_output += f\"<li>{line}</li>\"\n",
        "                    formatted_output += \"</ul>\"\n",
        "                else:\n",
        "                    formatted_output += f\"<p>{answer}</p>\"\n",
        "\n",
        "                if formatted_page_numbers:\n",
        "                    formatted_output += f\"<p><i>Source pages: {formatted_page_numbers}</i></p>\"\n",
        "\n",
        "            formatted_output += \"</div><hr>\"\n",
        "            return formatted_output, csv_filepath\n",
        "        else:\n",
        "            return \"No data to format.\", None\n",
        "   except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"An error occurred while formatting the output.\", None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMOowBFgO5gP"
      },
      "outputs": [],
      "source": [
        "def process_and_format(filepaths):\n",
        "    try:\n",
        "        data = process_pdf(filepaths)  # Get question-answer data\n",
        "        # Return error message, no CSV path\n",
        "        #df = pd.DataFrame(data, columns=[\"Question Number\", \"Question\", \"Response\",\"source_documents\"])  # Create DataFrame with proper column names\n",
        "        #with tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\", mode='w+', dir=os.getcwd()) as f:\n",
        "         #   df.to_csv(f.name, index=False)  # Save DataFrame to temporary CSV\n",
        "         #   csv_filepath = f.name  # Save the file path\n",
        "\n",
        "        formatted_output,csv_filepath = format_output(data)  # Format HTML output\n",
        "        return formatted_output, csv_filepath  # Return both outputs\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", None  # Return error message, no CSV path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saNMCCss5fsg"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    custom_css = \"\"\"\n",
        "    .header-text h1, .header-text h2 {\n",
        "        text-align: center;    }\n",
        "    .instruction-text {\n",
        "        text-align: justify;\n",
        "        margin: 20px;\n",
        "        font-size: 18px;\n",
        "    }\n",
        "    \"\"\"\n",
        "    theme = gr.themes.Soft(\n",
        "    primary_hue=\"teal\",\n",
        "    secondary_hue=\"teal\",\n",
        "    font=[gr.themes.GoogleFont('Poppins'), 'ui-sans-serif', 'system-ui', 'sans-serif'],\n",
        ").set(\n",
        "    # body_background_fill_dark='*neutral_200',\n",
        "    # body_text_color_dark='*neutral_950',\n",
        "    # body_text_color_subdued='*neutral_950',\n",
        "    # body_text_color_subdued_dark='*neutral_950',\n",
        "    # background_fill_primary_dark='*neutral_500',\n",
        "    # background_fill_secondary_dark='*neutral_50',\n",
        "    # color_accent_soft='*primary_300',\n",
        "    # color_accent_soft_dark='*neutral_900',\n",
        "    # button_primary_background_fill_hover_dark='*primary_600',\n",
        "    # button_primary_border_color='*primary_300',\n",
        "    # button_secondary_background_fill_dark='*primary_500',\n",
        "    # button_secondary_background_fill_hover_dark='*primary_950'\n",
        ")\n",
        "\n",
        "\n",
        "    # interface.launch()\n",
        "    with gr.Blocks(css=custom_css, theme=theme) as demo:\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                # Header texts\n",
        "                gr.HTML(\"<div class='header-text'><h1>Welcome to PDF Analyser</h1></div>\")\n",
        "                gr.HTML(\"<div class='header-text'><h2>Analysing Reports Made Easy</h2></div>\")\n",
        "                gr.HTML(\"<div class='header-text'><h3>Get insights from your PDF instantly</h3></div>\")\n",
        "\n",
        "                # File upload and results\n",
        "                uploaded_file = gr.Files(label=\"Upload a PDF\", file_count=\"multiple\", file_types=[\".pdf\"])\n",
        "                output_container = gr.HTML(label=\"Results\")\n",
        "                download_output = gr.File(label=\"Results\", type=\"filepath\")\n",
        "                # output_label = gr.HTML(\"<div class='header-text'><h4>Get insights from your PDF instantly</h4></div>\")\n",
        "\n",
        "                gr.Interface(\n",
        "                    fn=process_and_format,\n",
        "                    inputs=uploaded_file,\n",
        "                    outputs=[output_container, download_output],\n",
        "                    title=\"\",\n",
        "                    theme=theme,\n",
        "                    allow_flagging=\"auto\",\n",
        "                    description=\"Follow the instructions below.\"\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            # Instructions\n",
        "            gr.HTML(\"<div class='instruction-text'>\"\n",
        "                    \"<h2><strong>Instructions:</strong></h2><br>\"\n",
        "                    \"1. Upload the file and click on the submit button.<br>\"\n",
        "                    \"2. The insights will be available on the right side.<br>\"\n",
        "                    \"3. You can also download the provided insights.<br>\"\n",
        "                    \"4. Please wait until you see the output.\"\n",
        "                    \"</div>\")\n",
        "\n",
        "\n",
        "    demo.launch(debug=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}