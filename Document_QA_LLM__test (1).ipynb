{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o3FVJ-Z2i4a"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4joNjJTisXT",
        "outputId": "eacab862-a285-4e32-f6c6-ed663189256a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATkDCmIfcSrE"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-VIkh2Xr8zB"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZPIyYsZneh5"
      },
      "outputs": [],
      "source": [
        "! pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD9mlenT5_4Q"
      },
      "source": [
        "# Load Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YfIvvlFcD_v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "# sys.path.append('../..')\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbtLjKSo2-JS"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "\n",
        "    PyPDFLoader(\"/content/drive/MyDrive/Mercedes/mercedes-benz-annual-report-2022-incl-combined-management-report-mbg-ag-201-283.pdf\"),\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PolKLuwH6Ccz"
      },
      "source": [
        "# Split document into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "tNw_9G9c3Ink"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "text_splitter = TokenTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap =150\n",
        ")\n",
        "#text_splitter[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB86B1K35RpS"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrVn72Y8-qlK"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "langchain.debug = False\n",
        "\n",
        "#langchain.debug=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4htgCIwz5dv7",
        "outputId": "1c82fd86-709e-43c3-c3c0-35a84347c763"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md5pQMvS5gSD",
        "outputId": "4345475f-43fb-4083-9006-594e431b4f62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='Annual Report 2022', metadata={'source': '/content/mercedes-benz-annual-report-reduced.pdf', 'page': 0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwCu-GIv9Ziv"
      },
      "outputs": [],
      "source": [
        "splits[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV-s7oPt6HX5"
      },
      "source": [
        "# Initiate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ecxEP9X95htL"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36yNraLZnzZh"
      },
      "source": [
        "# Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9HwuAArTxE3"
      },
      "source": [
        "Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vThW_2Wlnx6T"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT3yorcu6KuU"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/chroma/'\n",
        "!rm -rf ./docs/chroma\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86FJFeKp7ebP"
      },
      "source": [
        "# Similarity Search (Explanation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUBpotLS7cmK",
        "outputId": "c0447f60-3c46-4778-a0b5-95882ac4406e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# question = \"Who is Chairman of the Supervisory Board of Mercedes-Benz Group AG\"\n",
        "# docs = vectordb.similarity_search(question,k=3)\n",
        "# len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfMaMY3XrpOz"
      },
      "outputs": [],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYnm6jWV8GOb"
      },
      "outputs": [],
      "source": [
        "docs[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SANaw4vzHDR2"
      },
      "outputs": [],
      "source": [
        "def get_context(question):\n",
        "    docs = vectordb1.similarity_search(question,k=5)\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4BB0F_-M_-H"
      },
      "outputs": [],
      "source": [
        "get_context(\"Any mergers?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiYXPFu8HENC"
      },
      "source": [
        "[link text](https://)# LLM model initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "XqBAJxKo8MnC"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.1)\n",
        "# llm.predict(\"what is ccsp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MkPzmdaQmsK"
      },
      "outputs": [],
      "source": [
        "def Query_from_user(qa_chain,questions):\n",
        "  print(questions)\n",
        "  for question in questions:\n",
        "    result = qa_chain({\"query\": question})\n",
        "    return result[\"result\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9p4UZbXTlyw"
      },
      "source": [
        "Chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHco2SPlHZNY"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
        "\n",
        "# Run chain\n",
        "from langchain.chains import RetrievalQA\n",
        "question = \"Any mergers?\"\n",
        "qa_chain = RetrievalQA.from_chain_type(llm,\n",
        "                                       retriever=vectordb.as_retriever(search_kwargs={\"k\": 5}),\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "Query_from_user(qa_chain,question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGPJvcv7s-MK"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Vj4iEZOZml"
      },
      "source": [
        "#Save the answers in a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7oIRqswfDqq",
        "outputId": "882829c4-682f-4f2e-ffb8-ede17d2cad5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your queries: - Any mergers?  - Any Acquisitions?\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
        "\n",
        "# Run chain\n",
        "from langchain.chains import RetrievalQA\n",
        "question = [str(question) for question in input(\"Enter your queries: \").split('?')]\n",
        "#print(question)\n",
        "qa_chain_multi = RetrievalQA.from_chain_type(llm,\n",
        "                                       retriever=vectordb.as_retriever(search_kwargs={\"k\": 5}),\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "\n",
        "#Query_from_user(qa_chain_multi,question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCvTU5q5lJc-"
      },
      "outputs": [],
      "source": [
        "with open(\"questions_and_answers_141_200_NEW.csv\", \"w\", newline=\"\") as file:  # Create file if it doesn't exist\n",
        "        csv_writer = csv.writer(file)\n",
        "        csv_writer.writerow([\"Question\", \"Answer\"])\n",
        "\n",
        "\n",
        "        for que in question:\n",
        "            result = qa_chain_multi({\"query\": que})\n",
        "            answer = result[\"result\"]\n",
        "            csv_writer.writerow([que, answer])\n",
        "\n",
        "        # Write the question and answer as a row in the CSV file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9STnNKYaD9N",
        "outputId": "6fd76322-1efa-41ae-a0ab-74a7889c383a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Any Acquisitions', '']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "IMHclD5Iw8Dt",
        "outputId": "4833a90c-5471-4fb5-f2b3-f359c269bbd9"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-91-d4b168fe4dc4>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-91-d4b168fe4dc4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def input_questions():\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "def input_questions():\n",
        "  #to handle the input and send it to the above cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLsKxCQF0ULn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1yF4dy1Tvho"
      },
      "source": [
        "FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI5VnyVkcXgc"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "vectordb1 = FAISS.from_documents(splits,embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTzQSh8R7fVV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build prompt\n",
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "{context}\n",
        "\n",
        "%questions%\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
        "\n",
        "# Run chain\n",
        "from langchain.chains import RetrievalQA\n",
        "question_f = \"Give all the chairmans mentioned in the report, which company report is this\"\n",
        "qa_chain_f = RetrievalQA.from_chain_type(llm,\n",
        "                                       retriever=vectordb1.as_retriever(search_kwargs={\"k\": 5}),\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
        "\n",
        "Query_from_user(qa_chain_f,question_f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}